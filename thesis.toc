\select@language {english}
\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}
\contentsline {section}{\numberline {1.1}Problem Definition}{3}{section.1.1}
\contentsline {section}{\numberline {1.2}Objectives}{3}{section.1.2}
\contentsline {section}{\numberline {1.3}Thesis Structure}{4}{section.1.3}
\contentsline {chapter}{\numberline {2}Theoretical Foundations}{5}{chapter.2}
\contentsline {section}{\numberline {2.1}Definitions}{5}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Queueing Theory}{5}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Workflow Processes}{5}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Reinforcement Learning}{5}{subsection.2.1.3}
\contentsline {subsection}{\numberline {2.1.4}Mixed Integer Linear Optimization}{5}{subsection.2.1.4}
\contentsline {subsection}{\numberline {2.1.5}Discrete Event Simulation}{5}{subsection.2.1.5}
\contentsline {section}{\numberline {2.2}Literature Overview}{5}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Queueing}{5}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Workflow}{6}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Reinforcement Learning}{7}{subsection.2.2.3}
\contentsline {subsection}{\numberline {2.2.4}Optimization}{8}{subsection.2.2.4}
\contentsline {subsection}{\numberline {2.2.5}Simulation}{9}{subsection.2.2.5}
\contentsline {section}{\numberline {2.3}Research Deficit}{9}{section.2.3}
\contentsline {chapter}{\numberline {3}Methodology}{11}{chapter.3}
\contentsline {section}{\numberline {3.1}Analysis Structure}{11}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Tools}{11}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Discrete event simulation using SimPy}{12}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}Analysis Environment}{12}{subsection.3.1.3}
\contentsline {subsubsection}{Start event}{13}{section*.8}
\contentsline {subsubsection}{User task}{14}{section*.9}
\contentsline {subsubsection}{Policy}{15}{section*.10}
\contentsline {section}{\numberline {3.2}Reinforcement Learning Analysis Environment}{20}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Reinforcement Learning}{20}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Finite Markov Decision Processes}{21}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Dynamic Programming}{22}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Monte Carlo Methods}{22}{subsection.3.2.4}
\contentsline {subsection}{\numberline {3.2.5}Temporal-Difference Learning}{22}{subsection.3.2.5}
\contentsline {subsection}{\numberline {3.2.6}On-policy Prediction with Approximation}{23}{subsection.3.2.6}
\contentsline {subsection}{\numberline {3.2.7}On-policy Control with Approximation}{24}{subsection.3.2.7}
\contentsline {subsection}{\numberline {3.2.8}Off-policy Methods with Approximation}{24}{subsection.3.2.8}
\contentsline {subsection}{\numberline {3.2.9}Policy Gradient Methods}{24}{subsection.3.2.9}
\contentsline {subsubsection}{Policy Gradient with Baseline}{25}{section*.11}
\contentsline {subsubsection}{Actor-Critic Policy Gradient}{26}{section*.12}
\contentsline {section}{\numberline {3.3}Hypothesis}{26}{section.3.3}
\contentsline {section}{\numberline {3.4}Data}{26}{section.3.4}
\contentsline {chapter}{\numberline {4}Empirical Analysis}{27}{chapter.4}
\contentsline {section}{\numberline {4.1}Results}{27}{section.4.1}
\contentsline {section}{\numberline {4.2}Discussion}{27}{section.4.2}
\contentsline {section}{\numberline {4.3}Research Contribution}{27}{section.4.3}
\contentsline {chapter}{\numberline {5}Conclusion}{29}{chapter.5}
\contentsline {section}{\numberline {5.1}Summary}{29}{section.5.1}
\contentsline {section}{\numberline {5.2}Resulting Conclusions}{29}{section.5.2}
\contentsline {section}{\numberline {5.3}Outlook}{29}{section.5.3}
\contentsline {chapter}{\numberline {A}First}{31}{appendix.A}
\contentsline {chapter}{\numberline {B}Second}{33}{appendix.B}
