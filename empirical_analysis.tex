\chapter{Empirical Analysis}
\label{ch:empirical_analysis}

In order to consistently and fairly evaluate all policies with the methods defined in \chpref{ch:policies}, the following methodology was put in place:
\begin{enumerate*}
	\item Each policy has its own simulation script that initializes a process that uses the predefined policy as means to solve role resolution
	\item Parameters are centrally defined
	\item Different \glspl{kpi} have been defined which are used to assert the efficiency of one policy against one another.
\end{enumerate*}

\section{Simulation Framework}

Each policy is simulated by means of simulation scripts. It  imports all required dependencies, initializes the \texttt{SimPy} discrete event simulation environment, the statistics file into which the policy job dumps all data during runtime, the policy itself to be used for role resolution and the process to be used. 

In order to assert comparability, parameters are centrally defined. \lstref{lst:central_parameters} shows the central parameters defined as global variables.

\begin{lstlisting}[caption=Global parameters definition which ensure comparability across simulation runs.,label=lst:central_parameters,style=CustomPython]
NUMBER_OF_USERS = 3
SERVICE_INTERVAL = 1
GENERATION_INTERVAL = 3
SIM_TIME = 1000
BATCH_SIZE = 5
TASK_VARIABILITY = 0.2 * SERVICE_INTERVAL
WORKER_VARIABILITY = 0.2 * SERVICE_INTERVAL
SEED = 2
\end{lstlisting}

The script initializes the chosen process and then calls the tokens generation method of the start event. Eventually the whole simulation is started by calling \texttt{SimPy}'s run method. A snippet of a simulation script can be found in \lstref{lst:simulation_script}.

\begin{lstlisting}[caption={Structure example of simulation framework using a K-Batch policy with \gls{dmf}. Initially dependencies are imported. Afterwards the discrete event simulation environment, a policy file for storing statistical data, a policy and a process returning its start event are initialized. Finally, by calling the environment's run method the simulation is started.},label=lst:simulation_script,style=CustomPython]
import simpy
from evaluation.statistics import calculate_statistics
from evaluation.subplot_evolution import evolution
from policies.optimization.batch.k_batch import K_BATCH
from simulations import *
from solvers.dmf_solver import dmf

policy_name = "{}_BATCH_DMF_NU{}_GI{}_SIM{}".format(BATCH_SIZE,NUMBER_OF_USERS, GENERATION_INTERVAL, SEED, SIM_TIME)
env = simpy.Environment()
file_policy = create_files("{}.csv".format(policy_name))
policy = K_BATCH(env, NUMBER_OF_USERS, WORKER_VARIABILITY, file_policy,BATCH_SIZE, dmf)
start_event = acquisition_process(env,policy,1,GENERATION_INTERVAL,False,None,None,None)
env.process(start_event.generate_tokens())
env.run(until=SIM_TIME)
file_policy.close()
calculate_statistics(file_policy.name, outfile=True)
evolution(file_policy.name, outfile=True)
\end{lstlisting}

\section{\glsentrylong{bpm}}

Two different types of processes have been defined:
\begin{enumerate*}
	\item A unitary process consisting of one start event, directly followed by one user task and eventually an end event (see \figref{fig:simple_process})
	\item A compound process modeled against a demonstration acquisition process used in real estate for properties acquisition (see \figref{fig:acquisition_process}).
\end{enumerate*}

\fig[0.5\textwidth]{simple_process}{Unitary process consisting of one start event, one user task and one end event.}{fig:simple_process}

\fig[\textwidth]{acquisition_process}{Demonstration acquisition process consisting of one start event, multiple user tasks, multiple decision gateways and two end events.}{fig:acquisition_process}

As described in \secref{sec:bpmn_implementation}, user tasks are the heart of each simulation. In each user task the policy has to solve the role resolution problem for each token reaching it. By focusing on a larger model, such as the one outlined in \figref{fig:acquisition_process} it is possible to simulate the policies in a ``real-world-like'' scenario. Furthermore, as explained in \subsecref{subsec:start_event}, the logical path flow for each token is manually prepared following a weighted probabilistic assignment and it gets designated to it. This approach permits to simulate only intrinsically correct paths. 

\section{\glsentrylongpl{kpi} and Data Visualization}

Based on \citet{Pinedo2008}'s and \citet{Zeng2005}'s definitions, different \glspl{kpi} have been defined to assert the efficacy of a policy, such as lateness, waiting time, service time, number of tokens completed, user loads and system load. Following the formal definitions of the per token $j$ \glspl{kpi} in respect to lateness $L_j$, wait time $w_j$, service time $p_{ij}$ of assigned user $i$ to token $j$, arrival time $A_j$, assignment time $a_j$, start time $S_j$ and finish time $F_j$.

\begin{align}
	L_j&=F_j-A_j \label{eq:lateness}\\
	w_j&=S_j-A_j \\
	p_{ij}&=F_j-S_j
\end{align}

Moreover, if we account for simulation time $T$, load $l_i$ of user $i$ is defined as the sum of all service times of tokens that have been assigned to him during the simulation divided by the total simulation time $T$, or formally:

\begin{equation}
	l_i=\frac{\sum_j p_{ij}}{T}
\end{equation}

and thus the average system load $\overline{l}$ over all $n$ users participating is defined as the average across all user's loads \ie

\begin{equation}
	\overline{l} = \frac{\sum_i l_i}{n}
\end{equation}

A summary plot with all \glspl{kpi} is done for each simulation script. \figref{fig:kpi_plot} shows an example of how this summary looks like.

\fig[\textwidth]{3_BATCH_MSA_NU2_GI3_SIM50_KPI}{\glsentryshortpl{kpi} summary plot for a 3-Batch policy using \glsentryshort{msa}, two users, generation interval set to $3$ and simulation time set to $50$. The left subgraph displays box plots for the \glsentryshortpl{kpi} lateness, wait time and service time and the orange box in the upper right corner shows the mean values. The right subgraph the histograms indicate the per user load while the dashed horizontal orange line indicates the average system load.}{fig:kpi_plot}

The left subplot in \figref{fig:kpi_plot} shows box plots for the three most importans \glspl{kpi} \ie $L_j$, $w_j$ and $p_{ij}$, and the right subplot shows the per user $i$ load $l_i$ and the average system load $\overline{l}$.

Additionally, for a more in depth visualization of a policy's performance, an evolution plot is also necessary. All types of policies share a common queues configuration, with a single global queue and a user specific queue. Each policy defines the maximal threshold a specific queue can reach. For a detailed explanation of the queues conformation refer to \chpref{ch:policies}.

The evolution plot shows the state change for the policy being analyzed by plotting the flow of a token across different user tasks. \figref{fig:evo_plot} shows such an example. Starting from the top, the initial box represents the state of the global queue over time $t$. We can see that for this specific simulation, the first token reaches the first user task called ``Setup Acquisition Offer'' around $t=5$. Around $t=10$ a second token reaches the same user task, which we can see from the fact that the size of the queue has grown up to $2$. Around $t=20$ we see a drop in the global queue size to $0$. If we compare the queues sizes underneath, which correspond to user 1 respectively user 2, we note that all three tokens have been successfully assigned: user 1 received 2 tokens while user 2 only 1. The change in color helps to identify at which user task a token is being worked.

\fig[\textwidth]{3_BATCH_MSA_NU2_GI3_SIM50_EVO}{Evolution plot for a 3-Batch policy using \glsentryshort{msa}, two users, generation interval set to $3$ and simulation time set to $50$. Each colored box corresponds to the quanity of tokens in the global respectively user queues.}{fig:evo_plot}

Finally, when comparing different policies between each other, \citet{Milo2012}'s definition of speedup $S$ between two quantities $q_1$ and $q_2$ is adopted, which he formally defines as the quotient: 

\begin{equation}
	S=\frac{q_1}{q_2}
\end{equation}
