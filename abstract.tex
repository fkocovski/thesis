\begin{abstract}

Efficiently assigning human resources \ie users, in workflow processes is a vital aspect when implementing workflow engines in corporate environments \citep{Cheng2000,Mentzas2001}. The traditional approach formulates a deterministic planning model using \gls{milp} and solve to optimality which has lead to promising results \citep{Zeng2005}. However this deterministic approach is a limiting factor when approaching the role resolution problem using \gls{milp} \citep{Zeng2005}.

This thesis expands on existing work in the field of effective role resolution in workflow processes by extending the already researched \gls{milp} methodologies and proposes a novel approach by introducing \gls{rl} based optimization approaches, which helps to overcome the deterministic limitations of \gls{milp} by approaching role resolution in a stochastic fashion \citep{Sutton2017}.

For evaluation a subset of \gls{bpmn} elements have been implemented in a discrete event simulation framework, in which existing policies for role resolution in workflow processes, such as \gls{sq}, \gls{llqp}, K-Batch and 1-Batch-1 are tested.

Both the extended \gls{milp} as well as the \gls{rl} based methods outperform the traditional approaches up to a $1.3$-fold speedup. Even though promising results have been obtained, precautions have to be taken when interpreting the results: on one hand the mathematical optimizations obtained are coupled with higher computational complexity which raise business trade-offs, on the other hand, \gls{rl} based optimizations overcome the computational complexity problem of the former but require lengthy training sessions in order to assert optimal convergence.

\gls{rl} based optimization methods lay the foundations for extensions by using alternative methods such as \gls{irl} \citep{Ng2000} and \gls{al} which promise to overcome the limitations of \gls{rl} methods by eliminating the requirement of internal reward functions and merely ``observing'' experts executing tasks and learning optimal behaviors from them \citep{Abbeel2004}. Future work could reconcile traditional \gls{milp} and \gls{al} based methods by using the former as the ``expert'' agent performing role resolution and \gls{al} methods would observe its behavior in order to learn from it.

\end{abstract}