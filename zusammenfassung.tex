\begin{otherlanguage}{ngerman}
	\begin{zusammenfassung}
	Die effiziente Zuteilung menschlicher Ressourcen \dhg Nutzer, in \glspl{wfms} ist ein zentraler Aspekt bei der Umsetzung von \glspl{wfms} in Gesellschaftsumgebungen \citep{Cheng2000,Mentzas2001}.

	Die übliche Methode formuliert ein deterministisches Planungsmodell mittels \gls{milp} und löst das Problem der Rollenauflösung nach Optimalität auf, welche zu vielversprechenden Resultate geführt hat \citep{Zeng2005}. Allerdings ist das deterministische Vorgehen den begrenzenden Faktor wenn man sich die Rollenauflösung mit \gls{milp} nähert \citep{Zeng2005}.

	Diese Masterarbeit erweitert die bestehende Forschung im Bereich der effektvollen Rollenauflösung in \glspl{wfms} indem \gls{milp}-Methoden ausgebaut wurden und einen neuartigen Ansatz mit \gls{rl} vorgestellt wurde \citep{Sutton2017}. Diese moderne Massnahmen mit \gls{rl} helfen bei der Überwindung der deterministischen Begrenzungen von \gls{milp} indem die Rollenauflösung stochastisch gelöst wird \citep{Sutton2017}.

	Es wurde eine Teilmenge von \gls{bpmn}-Elemente in einer diskreten Ereignisssimulationsumgebung für die Bewertung implementiert, wobei bestehende Policen für die Rollenauflösung in \glspl{wfms} \zbg \gls{sq}, \gls{llqp}, K-Batch und 1-Batch-1 getestet wurden.

	Sowohl die erweiterten \gls{milp} als auch die \gls{rl} basierten Methoden übertreffen die üblichen Massnahmen bis zu einem Beschleunigungsfaktor von $1.3$. Obwohl vielversprechende Resultate erreicht wurden, muss man die Interpretation der Resultate mit Vorsicht geniessen: die \gls{milp} basierten Methoden weisen einerseits höhere rechnerische Komplexität auf, welche Businesskompromisse aufwirft und anderseits überwinden die \gls{rl} basierten Methoden die rechnerische Komplexität der \gls{milp}-Methoden, diese verlangen jedoch langwierige Trainingssessionen um die optimale Konvergenz sicherzustellen.

	Die \gls{rl} basierten Methoden legen die Grundlagen für Erweiterungen mittels alternativer Methoden \zbg \gls{irl} \citep{Ng2000} und \gls{al} \citep{Abbeel2004} vor. \gls{al} verspricht die Einschränkungen der \gls{rl} basierten Methoden durch die Auflösung interner Entlohnungsfunktionen zu überwinden und lediglich optimale Verhalten durch die ``Beobachtung'' von Sachverständigen zu lernen \citep{Abbeel2004}. Künftige Arbeit konnte \gls{milp} und \gls{al} basierten Methoden abgleichen indem die erstere als Sachverständige verhält und die letztere das Verhalten der erstere beobachtet und lernt.
	\end{zusammenfassung}
\end{otherlanguage}