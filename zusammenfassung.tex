\begin{otherlanguage}{ngerman}
	\begin{zusammenfassung}
	Die effiziente Zuteilung menschlicher Ressourcen in \glspl{wfms} ist ein zentraler Aspekt bei der Umsetzung in Unternehmensumfeldern \citep{Cheng2000,Mentzas2001}.

	Die traditionelle Methode formuliert ein deterministisches Planungsmodell mittels \gls{milp} und löst das Problem der Rollenauflösung nach Optimalität auf, die zu vielversprechenden Resultaten geführt hat \citep{Zeng2005}. Allerdings ist das deterministische Vorgehen ein begrenzender Faktor, wenn man sich die Rollenauflösung mit \gls{milp} anschaut \citep{Zeng2005}.

	Diese Masterarbeit erweitert die bestehende Forschung im Bereich der effektvollen Rollenauflösung in \glspl{wfms} indem \gls{milp}-Methoden ausgebaut werden und ein neuartiger Ansatz mit \gls{rl} vorgestellt wird \citep{Sutton2017}. Der technologische Fortschritt durch \gls{rl} ermöglicht die Überwindung der deterministischen Begrenzungen von \gls{milp} indem die Rollenauflösung stochastisch gelöst wird \citep{Sutton2017}.

	In diesem Projekt wurde eine Teilmenge von \gls{bpmn}-Elemente in einem diskreten Ereignissimulationsumfeld für die Bewertung implementiert, wobei bestehende Policen für die Rollenauflösung in \glspl{wfms} \zbg \gls{sq}, \gls{llqp}, K-Batch und 1-Batch-1 getestet wurden.

	Sowohl die erweiterten \gls{milp} als auch die \gls{rl} basierten Policen übertreffen die traditionellen Methoden bis zu einem Beschleunigungsfaktor von $1.3$. Obwohl vielversprechende Resultate erreicht wurden, muss man die Interpretation der Resultate mit Vorsicht geniessen: die \gls{milp} basierten Methoden weisen einerseits eine höhere rechnerische Komplexität auf, die Businesskompromisse aufwirft. Anderseits überwinden die \gls{rl} basierten Methoden die rechnerische Komplexität der \gls{milp}-Methoden, diese verlangen jedoch langwierige Trainingseinheiten, um die optimale Konvergenz sicherzustellen.

	Die \gls{rl} basierten Methoden bilden die Grundlagen für Erweiterungen mittels alternativer Methoden wie \zbg \gls{irl} \citep{Ng2000} und \gls{al} \citep{Abbeel2004}. \gls{al} verspricht die Einschränkungen der \gls{rl} basierten Methoden durch die Auflösung interner Entlohnungsfunktionen zu überwinden und lernt das optimale Verhalten durch die ``Beobachtung'' von Sachverständigen \citep{Abbeel2004}. Künftige Arbeit könnte \gls{milp} und \gls{al} basierte Methoden abgleichen indem die Erstere sich als Sachverständige verhält und die Letztere das Verhalten der Ersteren beobachtet und von ihr lernt.
	\end{zusammenfassung}
\end{otherlanguage}